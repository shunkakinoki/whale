{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from https://github.com/radekosmulski/whale/blob/master/oversample.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage\n",
    "\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastprogress import force_console_behavior\n",
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fns = pd.read_pickle('../data/10_val_fns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "BS = 64\n",
    "NUM_WORKERS = 16\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '11-res50-full-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/10_oversampled_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train-extracted-224', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test-extracted-224'))\n",
    "        .transform(get_transforms(do_flip=False, max_zoom=1, max_warp=0, max_rotate=2), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (76174 items)\n",
       "x: ImageItemList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "w_0003639,w_0003639,w_0003639,w_0003639,w_0003639\n",
       "Path: ../data/train-extracted-224;\n",
       "\n",
       "Valid: LabelList (2931 items)\n",
       "x: ImageItemList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "w_cb622a2,w_8dddbee,w_8a6a8d5,w_3881f28,w_cee684e\n",
       "Path: ../data/train-extracted-224;\n",
       "\n",
       "Test: LabelList (7960 items)\n",
       "x: ImageItemList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ../data/train-extracted-224"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 950 ms, total: 5.25 s\n",
      "Wall time: 3.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048], model_dir=MODEL_PATH, metrics=[accuracy, map5])\n",
    "learn.clip_grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  map5    \n",
      "1         1.001561    6.261451    0.120778  0.160230  \n",
      "2         0.760604    6.496376    0.146025  0.185727  \n",
      "3         1.068263    7.850545    0.151484  0.196776  \n",
      "4         0.884718    7.761956    0.200273  0.253457  \n",
      "5         0.671748    6.976810    0.219720  0.276658  \n",
      "6         0.565592    6.803068    0.250768  0.309519  \n",
      "7         0.556764    7.263548    0.276015  0.336654  \n",
      "8         0.438798    7.460213    0.306721  0.369658  \n",
      "9         0.382827    7.761718    0.319686  0.383402  \n",
      "10        0.342217    7.476464    0.347663  0.413056  \n",
      "11        0.314645    7.364031    0.369157  0.432549  \n",
      "12        0.269172    7.358661    0.385534  0.451097  \n",
      "13        0.177433    7.373550    0.388946  0.451700  \n",
      "14        0.134167    6.715727    0.426817  0.488610  \n",
      "15        0.119350    6.276331    0.456499  0.518111  \n",
      "16        0.050575    5.648981    0.472876  0.533458  \n",
      "17        0.028072    5.464215    0.499147  0.560338  \n",
      "18        0.014686    5.029939    0.517230  0.573257  \n",
      "19        0.009996    4.605695    0.544524  0.598971  \n",
      "20        0.007123    4.315141    0.555783  0.611555  \n",
      "21        0.002228    4.031464    0.575913  0.627715  \n",
      "22        0.000617    3.938958    0.575913  0.630837  \n",
      "23        0.000287    3.873445    0.580689  0.635949  \n",
      "24        0.000686    3.873133    0.579666  0.635170  \n",
      "Total time: 1:37:42\n",
      "CPU times: user 1h 11min 47s, sys: 29min 44s, total: 1h 41min 31s\n",
      "Wall time: 1h 37min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(24, 1e-2)\n",
    "learn.save(f'{name}-stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  map5    \n",
      "1         0.000107    3.860171    0.580348  0.635841  \n",
      "2         0.000503    3.816877    0.586830  0.641192  \n",
      "3         0.001148    3.832558    0.586489  0.641584  \n",
      "4         0.001560    3.862892    0.584783  0.640185  \n",
      "5         0.000835    3.901370    0.575913  0.634618  \n",
      "6         0.000117    3.861731    0.585807  0.641340  \n",
      "7         0.000341    3.860297    0.584783  0.638809  \n",
      "8         0.000436    3.841269    0.586830  0.639059  \n",
      "9         0.000120    3.788567    0.586148  0.640902  \n",
      "10        0.000230    3.798464    0.590583  0.644063  \n",
      "11        0.000705    3.746600    0.593654  0.645127  \n",
      "12        0.000312    3.727324    0.596384  0.647310  \n",
      "13        0.000117    3.735152    0.597748  0.648169  \n",
      "14        0.000163    3.723325    0.595701  0.648266  \n",
      "15        0.000020    3.672943    0.597066  0.651160  \n",
      "16        0.000018    3.664675    0.593654  0.649016  \n",
      "17        0.000086    3.644717    0.596042  0.649704  \n",
      "18        0.000354    3.634622    0.599795  0.652348  \n",
      "19        0.000592    3.620657    0.604913  0.655851  \n",
      "20        0.000020    3.612935    0.608666  0.659400  \n",
      "21        0.000234    3.617636    0.608325  0.659428  \n",
      "22        0.000018    3.614699    0.611395  0.661100  \n",
      "23        0.000095    3.597908    0.610031  0.660292  \n",
      "24        0.000066    3.596827    0.610031  0.660332  \n",
      "Total time: 2:08:51\n",
      "CPU times: user 1h 33min 27s, sys: 39min 18s, total: 2h 12min 45s\n",
      "Wall time: 2h 8min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(24, lrs)\n",
    "learn.save(f'{name}-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224 * 2\n",
    "BS = 64 // 4\n",
    "NUM_WORKERS = 16\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train-extracted-448', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test-extracted-448'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (76174 items)\n",
       "x: ImageItemList\n",
       "Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448)\n",
       "y: CategoryList\n",
       "w_0003639,w_0003639,w_0003639,w_0003639,w_0003639\n",
       "Path: ../data/train-extracted-448;\n",
       "\n",
       "Valid: LabelList (2931 items)\n",
       "x: ImageItemList\n",
       "Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448)\n",
       "y: CategoryList\n",
       "w_cb622a2,w_8dddbee,w_8a6a8d5,w_3881f28,w_cee684e\n",
       "Path: ../data/train-extracted-448;\n",
       "\n",
       "Test: LabelList (7960 items)\n",
       "x: ImageItemList\n",
       "Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ../data/train-extracted-448"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.42 s, sys: 414 ms, total: 2.84 s\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048], model_dir=MODEL_PATH, metrics=[accuracy, map5])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-2')\n",
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  map5    \n",
      "1         0.585483    4.332168    0.472876  0.526612  \n",
      "2         0.253125    3.228748    0.546230  0.600807  \n",
      "3         0.543139    3.262885    0.514841  0.566678  \n",
      "4         0.946631    3.263905    0.507335  0.557466  \n",
      "5         0.845570    3.294701    0.504947  0.557876  \n",
      "6         0.828406    3.206880    0.508700  0.559189  \n",
      "7         0.598875    3.101036    0.543500  0.590737  \n",
      "8         0.537704    2.916110    0.570795  0.615535  \n",
      "9         0.414187    2.795772    0.622654  0.664227  \n",
      "10        0.412356    3.037873    0.651314  0.690174  \n",
      "11        0.539101    3.383638    0.699420  0.735870  \n",
      "12        0.453008    3.523456    0.714091  0.747111  \n",
      "Total time: 3:09:47\n",
      "CPU times: user 2h 21min 39s, sys: 56min 36s, total: 3h 18min 15s\n",
      "Wall time: 3h 9min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(12, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 486 Âµs, sys: 2.7 ms, total: 3.19 ms\n",
      "Wall time: 3.19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-4 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  accuracy  map5    \n",
      "1         0.462944    3.498866    0.710679  0.746554  \n",
      "2         0.467732    3.536111    0.720914  0.754503  \n",
      "3         0.460115    3.600281    0.727738  0.760213  \n",
      "4         0.480248    3.632361    0.732173  0.764301  \n",
      "5         0.577812    3.715545    0.740362  0.771062  \n",
      "6         0.647468    3.872792    0.735585  0.770630  \n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(22, lrs)\n",
    "learn.save(f'{name}-stage-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with oversampling\n",
    "df = pd.read_csv('../data/10_oversampled_train_and_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df, '../data/train-extracted-448', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test-extracted-448'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048], model_dir=MODEL_PATH, metrics=[accuracy, map5])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-4')\n",
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(2, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-4 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(3, lrs)\n",
    "learn.save(f'{name}-stage-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat((preds, torch.ones_like(preds[:, :1])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:, 5004] = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = learn.data.classes + ['new_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(preds, learn.data, name, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f'../subs/{name}.csv.gz').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f'../subs/{name}.csv.gz').Id.str.split().apply(lambda x: x[0] == 'new_whale').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c humpback-whale-identification -f subs/{name}.csv.gz -m \"{name}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
