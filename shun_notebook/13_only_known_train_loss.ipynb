{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from https://github.com/radekosmulski/whale/blob/master/oversample.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage\n",
    "\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastprogress import force_console_behavior\n",
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "      <td>w_f48451c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001f9222.jpg</td>\n",
       "      <td>w_c3d896a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00029d126.jpg</td>\n",
       "      <td>w_20df2c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00050a15a.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  0000e88ab.jpg  w_f48451c\n",
       "1  0001f9222.jpg  w_c3d896a\n",
       "2  00029d126.jpg  w_20df2c5\n",
       "3  00050a15a.jpg  new_whale\n",
       "4  0005c1ef8.jpg  new_whale"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fns = pd.read_pickle('../data/10_val_fns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "BS = 64\n",
    "NUM_WORKERS = 16\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '13-res50-full-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/10_oversampled_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train-extracted-224', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test-extracted-224'))\n",
    "        .transform(get_transforms(do_flip=False, max_zoom=1, max_warp=0, max_rotate=2), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (76174 items)\n",
       "x: ImageItemList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "w_0003639,w_0003639,w_0003639,w_0003639,w_0003639\n",
       "Path: ../data/train-extracted-224;\n",
       "\n",
       "Valid: LabelList (2931 items)\n",
       "x: ImageItemList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: CategoryList\n",
       "w_cb622a2,w_8dddbee,w_8a6a8d5,w_3881f28,w_cee684e\n",
       "Path: ../data/train-extracted-224;\n",
       "\n",
       "Test: LabelList (7960 items)\n",
       "x: ImageItemList\n",
       "Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224),Image (3, 224, 224)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ../data/train-extracted-224"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.1 s, sys: 1.03 s, total: 5.13 s\n",
      "Wall time: 3.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048], model_dir=MODEL_PATH)\n",
    "learn.clip_grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         0.975592    6.271087    \n",
      "2         0.772474    6.506855    \n",
      "3         1.080839    7.990137    \n",
      "4         0.906575    8.282987    \n",
      "5         0.631940    7.288753    \n",
      "6         0.570418    7.019714    \n",
      "7         0.551152    6.649921    \n",
      "8         0.480917    7.295500    \n",
      "9         0.391479    7.653440    \n",
      "10        0.342429    7.667839    \n",
      "11        0.321125    7.550643    \n",
      "12        0.220957    7.104164    \n",
      "13        0.180251    6.893097    \n",
      "14        0.166522    6.713761    \n",
      "15        0.101804    6.351599    \n",
      "16        0.055226    5.828933    \n",
      "17        0.026075    5.415598    \n",
      "18        0.019603    4.993219    \n",
      "19        0.009923    4.746617    \n",
      "20        0.001951    4.274943    \n",
      "21        0.000689    4.027005    \n",
      "22        0.002590    3.894199    \n",
      "23        0.000905    3.842482    \n",
      "24        0.000145    3.839142    \n",
      "Total time: 1:38:13\n",
      "CPU times: user 1h 7min 50s, sys: 29min 33s, total: 1h 37min 23s\n",
      "Wall time: 1h 38min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(24, 1e-2)\n",
    "learn.save(f'{name}-stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         0.001228    3.829298    \n",
      "2         0.000106    3.834505    \n",
      "3         0.000655    3.843672    \n",
      "4         0.000312    3.866990    \n",
      "5         0.000138    3.857727    \n",
      "6         0.000230    3.910743    \n",
      "7         0.000198    3.889875    \n",
      "8         0.000822    3.928916    \n",
      "9         0.000224    3.929289    \n",
      "10        0.000420    3.927934    \n",
      "11        0.001068    3.797371    \n",
      "12        0.000256    3.763932    \n",
      "13        0.001736    3.765885    \n",
      "14        0.000435    3.800071    \n",
      "15        0.000141    3.755549    \n",
      "16        0.000191    3.728598    \n",
      "17        0.000104    3.708236    \n",
      "18        0.000019    3.665085    \n",
      "19        0.000030    3.655184    \n",
      "20        0.000010    3.632715    \n",
      "21        0.000130    3.632558    \n",
      "22        0.000015    3.619079    \n",
      "23        0.000062    3.618154    \n",
      "24        0.000035    3.645159    \n",
      "Total time: 2:09:44\n",
      "CPU times: user 1h 29min 44s, sys: 39min 14s, total: 2h 8min 59s\n",
      "Wall time: 2h 9min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(24, lrs)\n",
    "learn.save(f'{name}-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224 * 2\n",
    "BS = 64 // 4\n",
    "NUM_WORKERS = 16\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train-extracted-448', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test-extracted-448'))\n",
    "        .transform(get_transforms(do_flip=False, max_zoom=1, max_warp=0, max_rotate=2), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (76174 items)\n",
       "x: ImageItemList\n",
       "Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448)\n",
       "y: CategoryList\n",
       "w_0003639,w_0003639,w_0003639,w_0003639,w_0003639\n",
       "Path: ../data/train-extracted-448;\n",
       "\n",
       "Valid: LabelList (2931 items)\n",
       "x: ImageItemList\n",
       "Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448)\n",
       "y: CategoryList\n",
       "w_cb622a2,w_8dddbee,w_8a6a8d5,w_3881f28,w_cee684e\n",
       "Path: ../data/train-extracted-448;\n",
       "\n",
       "Test: LabelList (7960 items)\n",
       "x: ImageItemList\n",
       "Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448),Image (3, 448, 448)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ../data/train-extracted-448"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.83 s, sys: 1.26 s, total: 5.09 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048], model_dir=MODEL_PATH)\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-2')\n",
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(10, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-3-10')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(3, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-3-10-2')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(14, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-3-10-3')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learn.fit_one_cycle(22, lrs)\n",
    "learn.save(f'{name}-stage-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with oversampling\n",
    "df = pd.read_csv('../data/10_oversampled_train_and_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df, '../data/train-extracted-448', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test-extracted-448'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048], model_dir=MODEL_PATH)\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-4')\n",
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(2, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "learn.fit_one_cycle(3, lrs)\n",
    "learn.save(f'{name}-stage-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat((preds, torch.ones_like(preds[:, :1])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:, 5004] = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = learn.data.classes + ['new_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(preds, learn.data, name, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ef60d186c.jpg</td>\n",
       "      <td>w_83cc0ec new_whale w_0815d2c w_73d71d2 w_6df47c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e141fd305.jpg</td>\n",
       "      <td>new_whale w_a10e633 w_76a45de w_1788910 w_be5ee58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25045eeda.jpg</td>\n",
       "      <td>w_5d5c6a6 new_whale w_9da1811 w_00904a7 w_56fe328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d11ed8266.jpg</td>\n",
       "      <td>w_f765256 new_whale w_aa0dacc w_a8b34a0 w_23e1d57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98e1ea193.jpg</td>\n",
       "      <td>w_f971ecb w_f47f214 new_whale w_51e7506 w_aa0dacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image                                                 Id\n",
       "0  ef60d186c.jpg  w_83cc0ec new_whale w_0815d2c w_73d71d2 w_6df47c6\n",
       "1  e141fd305.jpg  new_whale w_a10e633 w_76a45de w_1788910 w_be5ee58\n",
       "2  25045eeda.jpg  w_5d5c6a6 new_whale w_9da1811 w_00904a7 w_56fe328\n",
       "3  d11ed8266.jpg  w_f765256 new_whale w_aa0dacc w_a8b34a0 w_23e1d57\n",
       "4  98e1ea193.jpg  w_f971ecb w_f47f214 new_whale w_51e7506 w_aa0dacc"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'../subs/{name}.csv.gz').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13655778894472362"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'../subs/{name}.csv.gz').Id.str.split().apply(lambda x: x[0] == 'new_whale').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 170k/170k [00:07<00:00, 23.8kB/s]\n",
      "Successfully submitted to Humpback Whale Identification"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c humpback-whale-identification -f ../subs/{name}.csv.gz -m \"{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
