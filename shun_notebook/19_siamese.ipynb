{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is taken from https://www.kaggle.com/voglinio/siamese-two-pretrained-weights-0-855"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "# Read or generate p2h, a dictionary of image name to image id (picture to hash)\n",
    "import pickle\n",
    "import platform\n",
    "import random\n",
    "# Suppress annoying stderr output when importing keras.\n",
    "import sys\n",
    "from lap import lapjv\n",
    "from math import sqrt\n",
    "# Determine the size of each image\n",
    "from os.path import isfile\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image as pil_image\n",
    "from imagehash import phash\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.engine.topology import Input\n",
    "from keras.layers import Activation, Add, BatchNormalization, Concatenate, Conv2D, Dense, Flatten, GlobalMaxPooling2D, \\\n",
    "    Lambda, MaxPooling2D, Reshape\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import Sequence\n",
    "from pandas import read_csv\n",
    "from scipy.ndimage import affine_transform\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = '../data/train.csv'\n",
    "SUB_DF = '../data/sample_submission.csv'\n",
    "TRAIN = '../data/train/'\n",
    "TEST = '../data/test/'\n",
    "P2H = '../data/metadata/p2h.pickle'\n",
    "P2SIZE = '../data/metadata/p2size.pickle'\n",
    "BB_DF = \"../data/metadata/bounding_boxes.csv\"\n",
    "tagged = dict([(p, w) for _, p, w in read_csv(TRAIN_DF).to_records()])\n",
    "submit = [p for _, p, _ in read_csv(SUB_DF).to_records()]\n",
    "join = list(tagged.keys()) + submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_path(p):\n",
    "    if isfile(TRAIN + p):\n",
    "        return TRAIN + p\n",
    "    if isfile(TEST + p):\n",
    "        return TEST + p\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2SIZE exists.\n"
     ]
    }
   ],
   "source": [
    "### LOADING\n",
    "if isfile(P2SIZE):\n",
    "    print(\"P2SIZE exists.\")\n",
    "    with open(P2SIZE, 'rb') as f:\n",
    "        p2size = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### CREATE\n",
    "p2size = {}\n",
    "for p in tqdm(join):\n",
    "    size = pil_image.open(expand_path(p)).size\n",
    "    p2size[p] = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### COMPARE PICKLES\n",
    "# value = { k : p2size_pickle[k] for k in set(p2size_pickle) - set(p2size) }\n",
    "# value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(h1, h2):\n",
    "    for p1 in h2ps[h1]:\n",
    "        for p2 in h2ps[h2]:\n",
    "            i1 = pil_image.open(expand_path(p1))\n",
    "            i2 = pil_image.open(expand_path(p2))\n",
    "            if i1.mode != i2.mode or i1.size != i2.size: return False\n",
    "            a1 = np.array(i1)\n",
    "            a1 = a1 - a1.mean()\n",
    "            a1 = a1 / sqrt((a1 ** 2).mean())\n",
    "            a2 = np.array(i2)\n",
    "            a2 = a2 - a2.mean()\n",
    "            a2 = a2 / sqrt((a2 ** 2).mean())\n",
    "            a = ((a1 - a2) ** 2).mean()\n",
    "            if a > 0.1: return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2H exists.\n"
     ]
    }
   ],
   "source": [
    "### LOADING\n",
    "if isfile(P2H):\n",
    "    print(\"P2H exists.\")\n",
    "    with open(P2H, 'rb') as f:\n",
    "        p2h = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### CREATE\n",
    "# Compute phash for each image in the training and test set.\n",
    "p2h = {}\n",
    "for p in tqdm(join):\n",
    "    img = pil_image.open(expand_path(p))\n",
    "    h = phash(img)\n",
    "    p2h[p] = h\n",
    "\n",
    "# Find all images associated with a given phash value.\n",
    "h2ps = {}\n",
    "for p, h in p2h.items():\n",
    "    if h not in h2ps: h2ps[h] = []\n",
    "    if p not in h2ps[h]: h2ps[h].append(p)\n",
    "\n",
    "# Find all distinct phash values\n",
    "hs = list(h2ps.keys())\n",
    "\n",
    "# If the images are close enough, associate the two phash values (this is the slow part: n^2 algorithm)\n",
    "h2h = {}\n",
    "for i, h1 in enumerate(tqdm(hs)):\n",
    "    for h2 in hs[:i]:\n",
    "        if h1 - h2 <= 6 and match(h1, h2):\n",
    "            s1 = str(h1)\n",
    "            s2 = str(h2)\n",
    "            if s1 < s2: s1, s2 = s2, s1\n",
    "            h2h[s1] = s2\n",
    "\n",
    "# Group together images with equivalent phash, and replace by string format of phash (faster and more readable)\n",
    "for p, h in p2h.items():\n",
    "    h = str(h)\n",
    "    if h in h2h: h = h2h[h]\n",
    "    p2h[p] = h"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### CREATE PICKLE\n",
    "with open('../data/metadata/p2h_original.pickle', 'wb') as f:\n",
    "    pickle.dump(p2h, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### COMPARE PICKLES\n",
    "# value = { k : p2h_pickle[k] for k in set(p2h_pickle) - set(p2h) }\n",
    "# value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each image id, determine the list of pictures\n",
    "h2ps = {}\n",
    "for p, h in p2h.items():\n",
    "    if h not in h2ps: h2ps[h] = []\n",
    "    if p not in h2ps[h]: h2ps[h].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eecad0b52d4ac2f0 ['01f66ca26.jpg', 'd37179fd1.jpg']\n",
      "afdac0b52a5a82b5 ['579886448.jpg', 'f50529c53.jpg']\n",
      "94216bb289ccd63f ['60a3f2422.jpg', '7f7a63b8a.jpg']\n",
      "ad4ac2b43d0fcaf0 ['b95d73a55.jpg', 'fb3879dc7.jpg']\n"
     ]
    }
   ],
   "source": [
    "### MULTIPLE PICTURE ITEMS IN H2PS\n",
    "\n",
    "for h, ps in h2ps.items():\n",
    "    if len(ps) > 1:\n",
    "        print(h, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_whale(imgs, per_row=2):\n",
    "    n = len(imgs)\n",
    "    rows = (n + per_row - 1) // per_row\n",
    "    cols = min(per_row, n)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(24 // per_row * cols, 24 // per_row * rows))\n",
    "    for ax in axes.flatten(): ax.axis('off')\n",
    "    for i, (img, ax) in enumerate(zip(imgs, axes.flatten())): ax.imshow(img.convert('RGB'))\n",
    "        \n",
    "\n",
    "def read_raw_image(p):\n",
    "    img = pil_image.open(expand_path(p))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each images id, select the prefered image\n",
    "def prefer(ps):\n",
    "    if len(ps) == 1: return ps[0]\n",
    "    best_p = ps[0]\n",
    "    best_s = p2size[best_p]\n",
    "    for i in range(1, len(ps)):\n",
    "        p = ps[i]\n",
    "        s = p2size[p]\n",
    "        if s[0] * s[1] > best_s[0] * best_s[1]:  # Select the image with highest resolution\n",
    "            best_p = p\n",
    "            best_s = s\n",
    "    return best_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2p = {}\n",
    "for h, ps in h2ps.items():\n",
    "    h2p[h] = prefer(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33317,\n",
       " [('d26698c3271c757c', '0000e88ab.jpg'),\n",
       "  ('ba8cc231ad489b77', '0001f9222.jpg'),\n",
       "  ('bbcad234a52d0f0b', '00029d126.jpg'),\n",
       "  ('c09ae7dc09f33a29', '00050a15a.jpg'),\n",
       "  ('d02f65ba9f74a08a', '0005c1ef8.jpg')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h2p), list(h2p.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the bounding box data from the bounding box kernel (see reference above)\n",
    "p2bb = pd.read_csv(BB_DF).set_index(\"Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_stderr = sys.stderr\n",
    "sys.stderr = open('/dev/null' if platform.system() != 'Windows' else 'nul', 'w')\n",
    "\n",
    "sys.stderr = old_stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (384, 384, 1)  # The image shape used by the model\n",
    "anisotropy = 2.15  # The horizontal compression ratio\n",
    "crop_margin = 0.05  # The margin added around the bounding box to compensate for bounding box inaccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transform(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    \"\"\"\n",
    "    Build a transformation matrix with the specified characteristics.\n",
    "    \"\"\"\n",
    "    rotation = np.deg2rad(rotation)\n",
    "    shear = np.deg2rad(shear)\n",
    "    rotation_matrix = np.array(\n",
    "        [[np.cos(rotation), np.sin(rotation), 0], [-np.sin(rotation), np.cos(rotation), 0], [0, 0, 1]])\n",
    "    shift_matrix = np.array([[1, 0, height_shift], [0, 1, width_shift], [0, 0, 1]])\n",
    "    shear_matrix = np.array([[1, np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]])\n",
    "    zoom_matrix = np.array([[1.0 / height_zoom, 0, 0], [0, 1.0 / width_zoom, 0], [0, 0, 1]])\n",
    "    shift_matrix = np.array([[1, 0, -height_shift], [0, 1, -width_shift], [0, 0, 1]])\n",
    "    return np.dot(np.dot(rotation_matrix, shear_matrix), np.dot(zoom_matrix, shift_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cropped_image(p, augment):\n",
    "    \"\"\"\n",
    "    @param p : the name of the picture to read\n",
    "    @param augment: True/False if data augmentation should be performed\n",
    "    @return a numpy array with the transformed image\n",
    "    \"\"\"\n",
    "    # If an image id was given, convert to filename\n",
    "    if p in h2p:\n",
    "        p = h2p[p]\n",
    "    size_x, size_y = p2size[p]\n",
    "\n",
    "    # Determine the region of the original image we want to capture based on the bounding box.\n",
    "    row = p2bb.loc[p]\n",
    "    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "    dx = x1 - x0\n",
    "    dy = y1 - y0\n",
    "    x0 -= dx * crop_margin\n",
    "    x1 += dx * crop_margin + 1\n",
    "    y0 -= dy * crop_margin\n",
    "    y1 += dy * crop_margin + 1\n",
    "    if x0 < 0:\n",
    "        x0 = 0\n",
    "    if x1 > size_x:\n",
    "        x1 = size_x\n",
    "    if y0 < 0:\n",
    "        y0 = 0\n",
    "    if y1 > size_y:\n",
    "        y1 = size_y\n",
    "    dx = x1 - x0\n",
    "    dy = y1 - y0\n",
    "    if dx > dy * anisotropy:\n",
    "        dy = 0.5 * (dx / anisotropy - dy)\n",
    "        y0 -= dy\n",
    "        y1 += dy\n",
    "    else:\n",
    "        dx = 0.5 * (dy * anisotropy - dx)\n",
    "        x0 -= dx\n",
    "        x1 += dx\n",
    "\n",
    "    # Generate the transformation matrix\n",
    "    trans = np.array([[1, 0, -0.5 * img_shape[0]], [0, 1, -0.5 * img_shape[1]], [0, 0, 1]])\n",
    "    trans = np.dot(np.array([[(y1 - y0) / img_shape[0], 0, 0], [0, (x1 - x0) / img_shape[1], 0], [0, 0, 1]]), trans)\n",
    "    if augment:\n",
    "        trans = np.dot(build_transform(\n",
    "            random.uniform(-5, 5),\n",
    "            random.uniform(-5, 5),\n",
    "            random.uniform(0.8, 1.0),\n",
    "            random.uniform(0.8, 1.0),\n",
    "            random.uniform(-0.05 * (y1 - y0), 0.05 * (y1 - y0)),\n",
    "            random.uniform(-0.05 * (x1 - x0), 0.05 * (x1 - x0))\n",
    "        ), trans)\n",
    "    trans = np.dot(np.array([[1, 0, 0.5 * (y1 + y0)], [0, 1, 0.5 * (x1 + x0)], [0, 0, 1]]), trans)\n",
    "\n",
    "    # Read the image, transform to black and white and comvert to numpy array\n",
    "    img = read_raw_image(p).convert('L')\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    # Apply affine transformation\n",
    "    matrix = trans[:2, :2]\n",
    "    offset = trans[:2, 2]\n",
    "    img = img.reshape(img.shape[:-1])\n",
    "    img = affine_transform(img, matrix, offset, output_shape=img_shape[:-1], order=1, mode='constant',\n",
    "                           cval=np.average(img))\n",
    "    img = img.reshape(img_shape)\n",
    "\n",
    "    # Normalize to zero mean and unit variance\n",
    "    img -= np.mean(img, keepdims=True)\n",
    "    img /= np.std(img, keepdims=True) + K.epsilon()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_for_training(p):\n",
    "    \"\"\"\n",
    "    Read and preprocess an image with data augmentation (random transform).\n",
    "    \"\"\"\n",
    "    return read_cropped_image(p, True)\n",
    "\n",
    "\n",
    "def read_for_validation(p):\n",
    "    \"\"\"\n",
    "    Read and preprocess an image without data augmentation (use for testing).\n",
    "    \"\"\"\n",
    "    return read_cropped_image(p, False)\n",
    "\n",
    "\n",
    "p = list(tagged.keys())[312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subblock(x, filter, **kwargs):\n",
    "    x = BatchNormalization()(x)\n",
    "    y = x\n",
    "    y = Conv2D(filter, (1, 1), activation='relu', **kwargs)(y)  # Reduce the number of features to 'filter'\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Conv2D(filter, (3, 3), activation='relu', **kwargs)(y)  # Extend the feature field\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Conv2D(K.int_shape(x)[-1], (1, 1), **kwargs)(y)  # no activation # Restore the number of original features\n",
    "    y = Add()([x, y])  # Add the bypass connection\n",
    "    y = Activation('relu')(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def build_model(lr, l2, activation='sigmoid'):\n",
    "    ##############\n",
    "    # BRANCH MODEL\n",
    "    ##############\n",
    "    regul = regularizers.l2(l2)\n",
    "    optim = Adam(lr=lr)\n",
    "    kwargs = {'padding': 'same', 'kernel_regularizer': regul}\n",
    "\n",
    "    inp = Input(shape=img_shape)  # 384x384x1\n",
    "    x = Conv2D(64, (9, 9), strides=2, activation='relu', **kwargs)(inp)\n",
    "\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)  # 96x96x64\n",
    "    for _ in range(2):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', **kwargs)(x)\n",
    "\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)  # 48x48x64\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (1, 1), activation='relu', **kwargs)(x)  # 48x48x128\n",
    "    for _ in range(4):\n",
    "        x = subblock(x, 64, **kwargs)\n",
    "\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)  # 24x24x128\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, (1, 1), activation='relu', **kwargs)(x)  # 24x24x256\n",
    "    for _ in range(4):\n",
    "        x = subblock(x, 64, **kwargs)\n",
    "\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)  # 12x12x256\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(384, (1, 1), activation='relu', **kwargs)(x)  # 12x12x384\n",
    "    for _ in range(4):\n",
    "        x = subblock(x, 96, **kwargs)\n",
    "\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)  # 6x6x384\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, (1, 1), activation='relu', **kwargs)(x)  # 6x6x512\n",
    "    for _ in range(4):\n",
    "        x = subblock(x, 128, **kwargs)\n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)  # 512\n",
    "    branch_model = Model(inp, x)\n",
    "\n",
    "    ############\n",
    "    # HEAD MODEL\n",
    "    ############\n",
    "    mid = 32\n",
    "    xa_inp = Input(shape=branch_model.output_shape[1:])\n",
    "    xb_inp = Input(shape=branch_model.output_shape[1:])\n",
    "    x1 = Lambda(lambda x: x[0] * x[1])([xa_inp, xb_inp])\n",
    "    x2 = Lambda(lambda x: x[0] + x[1])([xa_inp, xb_inp])\n",
    "    x3 = Lambda(lambda x: K.abs(x[0] - x[1]))([xa_inp, xb_inp])\n",
    "    x4 = Lambda(lambda x: K.square(x))(x3)\n",
    "    x = Concatenate()([x1, x2, x3, x4])\n",
    "    x = Reshape((4, branch_model.output_shape[1], 1), name='reshape1')(x)\n",
    "\n",
    "    # Per feature NN with shared weight is implemented using CONV2D with appropriate stride.\n",
    "    x = Conv2D(mid, (4, 1), activation='relu', padding='valid')(x)\n",
    "    x = Reshape((branch_model.output_shape[1], mid, 1))(x)\n",
    "    x = Conv2D(1, (1, mid), activation='linear', padding='valid')(x)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "\n",
    "    # Weighted sum implemented as a Dense layer.\n",
    "    x = Dense(1, use_bias=True, activation=activation, name='weighted-average')(x)\n",
    "    head_model = Model([xa_inp, xb_inp], x, name='head')\n",
    "\n",
    "    ########################\n",
    "    # SIAMESE NEURAL NETWORK\n",
    "    ########################\n",
    "    # Complete model is constructed by calling the branch model on each input image,\n",
    "    # and then the head model on the resulting 512-vectors.\n",
    "    img_a = Input(shape=img_shape)\n",
    "    img_b = Input(shape=img_shape)\n",
    "    xa = branch_model(img_a)\n",
    "    xb = branch_model(img_b)\n",
    "    x = head_model([xa, xb])\n",
    "    model = Model([img_a, img_b], x)\n",
    "    model.compile(optim, loss='binary_crossentropy', metrics=['binary_crossentropy', 'acc'])\n",
    "    return model, branch_model, head_model\n",
    "\n",
    "\n",
    "model, branch_model, head_model = build_model(64e-5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2ws = {}\n",
    "new_whale = 'new_whale'\n",
    "for p, w in tagged.items():\n",
    "    if w != new_whale:  # Use only identified whales\n",
    "        h = p2h[p]\n",
    "        if h not in h2ws: h2ws[h] = []\n",
    "        if w not in h2ws[h]: h2ws[h].append(w)\n",
    "for h, ws in h2ws.items():\n",
    "    if len(ws) > 1:\n",
    "        h2ws[h] = sorted(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15696,\n",
       " [('d26698c3271c757c', ['w_f48451c']),\n",
       "  ('ba8cc231ad489b77', ['w_c3d896a']),\n",
       "  ('bbcad234a52d0f0b', ['w_20df2c5']),\n",
       "  ('e91b8cc2f270723d', ['w_dd88965']),\n",
       "  ('e99a96243f89711e', ['w_64404ac'])])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h2ws), list(h2ws.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each whale, find the unambiguous images ids.\n",
    "w2hs = {}\n",
    "for h, ws in h2ws.items():\n",
    "    if len(ws) == 1:  # Use only unambiguous pictures\n",
    "        w = ws[0]\n",
    "        if w not in w2hs: w2hs[w] = []\n",
    "        if h not in w2hs[w]: w2hs[w].append(h)\n",
    "for w, hs in w2hs.items():\n",
    "    if len(hs) > 1:\n",
    "        w2hs[w] = sorted(hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5004,\n",
       " [('w_f48451c',\n",
       "   ['93436cbc5a879761',\n",
       "    '96b1699e46397c92',\n",
       "    '96d9ac9bc62dc1c2',\n",
       "    'a2ddce3324c8bc0f',\n",
       "    'afcbd0302fcd9033',\n",
       "    'b08f8e73332cccc3',\n",
       "    'b0cf8c3376ac511b',\n",
       "    'b3e81cc92330decd',\n",
       "    'b688cd3332e4cc9b',\n",
       "    'ba9899aa9a597a26',\n",
       "    'c1363f8d27b8986c',\n",
       "    'c79a69c31e638c3c',\n",
       "    'd0be5cb26790c83d',\n",
       "    'd26698c3271c757c']),\n",
       "  ('w_c3d896a',\n",
       "   ['b33cced372343131',\n",
       "    'ba8cc231ad489b77',\n",
       "    'bacac4b53d484a73',\n",
       "    'ead4952568da7634']),\n",
       "  ('w_20df2c5',\n",
       "   ['8fc0f53588fb2a4a',\n",
       "    'b98ad332b529cc39',\n",
       "    'bbcad234a52d0f0b',\n",
       "    'fa17c07078391e97'])])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2hs), list(w2hs.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []  # A list of training image ids\n",
    "for hs in w2hs.values():\n",
    "    if len(hs) > 1:\n",
    "        train += hs\n",
    "random.shuffle(train)\n",
    "train_set = set(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13623,\n",
       " ['df3881c2e4795f0a',\n",
       "  'ea5a9525691a87e5',\n",
       "  'eece81f0b234acac',\n",
       "  'fa95807095699e4f',\n",
       "  'bbc6a469993c4e32'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), list(train_set)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2ts = {}  # Associate the image ids from train to each whale id.\n",
    "for w, hs in w2hs.items():\n",
    "    for h in hs:\n",
    "        if h in train_set:\n",
    "            if w not in w2ts:\n",
    "                w2ts[w] = []\n",
    "            if h not in w2ts[w]:\n",
    "                w2ts[w].append(h)\n",
    "for w, ts in w2ts.items():\n",
    "    w2ts[w] = np.array(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2931,\n",
       " [('w_f48451c',\n",
       "   array(['93436cbc5a879761', '96b1699e46397c92', '96d9ac9bc62dc1c2',\n",
       "          'a2ddce3324c8bc0f', 'afcbd0302fcd9033', 'b08f8e73332cccc3',\n",
       "          'b0cf8c3376ac511b', 'b3e81cc92330decd', 'b688cd3332e4cc9b',\n",
       "          'ba9899aa9a597a26', 'c1363f8d27b8986c', 'c79a69c31e638c3c',\n",
       "          'd0be5cb26790c83d', 'd26698c3271c757c'], dtype='<U16')),\n",
       "  ('w_c3d896a',\n",
       "   array(['b33cced372343131', 'ba8cc231ad489b77', 'bacac4b53d484a73',\n",
       "          'ead4952568da7634'], dtype='<U16')),\n",
       "  ('w_20df2c5',\n",
       "   array(['8fc0f53588fb2a4a', 'b98ad332b529cc39', 'bbcad234a52d0f0b',\n",
       "          'fa17c07078391e97'], dtype='<U16')),\n",
       "  ('w_dd88965',\n",
       "   array(['a86986d6b03b6fc4', 'a9c4956a562d8cbb', 'ad88d2b06f727c89',\n",
       "          'bc4ed0f2a7e168a8', 'bcc19067bc28cb3e', 'bcc5c27249b48d7a',\n",
       "          'bdc0d327259c68da', 'bdc0d427e0b8c9ba', 'da8582702dcb62bf',\n",
       "          'e89d9662719c4e93', 'e8d985f13e25c887', 'e91b8cc2f270723d',\n",
       "          'ea8781f2b47da80b', 'ea9986e2b0e81dec', 'ea9d8660b0699d6e',\n",
       "          'ea9d8662707999d2'], dtype='<U16')),\n",
       "  ('w_64404ac',\n",
       "   array(['a880c67f5dd82e87', 'b8cbc6f42dbb0846', 'b940d63ec9b9e449',\n",
       "          'e96a968625399ace', 'e99a96243f89711e'], dtype='<U16'))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2ts), list(w2ts.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2i = {}  # The position in train of each training image id\n",
    "for i, t in enumerate(train):\n",
    "    t2i[t] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13623,\n",
       " [('eadb98a5e1781c0d', 0),\n",
       "  ('eb9ec9f28520b525', 1),\n",
       "  ('927a6d8d9b36244d', 2),\n",
       "  ('f84ad3a1e232b4ad', 3),\n",
       "  ('e8d885e3b2c3acd1', 4)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t2i), list(t2i.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingData(Sequence):\n",
    "    def __init__(self, score, steps=1000, batch_size=32):\n",
    "        \"\"\"\n",
    "        @param score the cost matrix for the picture matching\n",
    "        @param steps the number of epoch we are planning with this score matrix\n",
    "        \"\"\"\n",
    "        super(TrainingData, self).__init__()\n",
    "        self.score = -score  # Maximizing the score is the same as minimizing -score.\n",
    "        self.steps = steps\n",
    "        self.batch_size = batch_size\n",
    "        for ts in w2ts.values():\n",
    "            idxs = [t2i[t] for t in ts]\n",
    "            for i in idxs:\n",
    "                for j in idxs:\n",
    "                    self.score[\n",
    "                        i, j] = 10000.0  # Set a large value for matching whales -- eliminates this potential pairing\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = self.batch_size * index\n",
    "        end = min(start + self.batch_size, len(self.match) + len(self.unmatch))\n",
    "        size = end - start\n",
    "        assert size > 0\n",
    "        a = np.zeros((size,) + img_shape, dtype=K.floatx())\n",
    "        b = np.zeros((size,) + img_shape, dtype=K.floatx())\n",
    "        c = np.zeros((size, 1), dtype=K.floatx())\n",
    "        j = start // 2\n",
    "        for i in range(0, size, 2):\n",
    "            a[i, :, :, :] = read_for_training(self.match[j][0])\n",
    "            b[i, :, :, :] = read_for_training(self.match[j][1])\n",
    "            c[i, 0] = 1  # This is a match\n",
    "            a[i + 1, :, :, :] = read_for_training(self.unmatch[j][0])\n",
    "            b[i + 1, :, :, :] = read_for_training(self.unmatch[j][1])\n",
    "            c[i + 1, 0] = 0  # Different whales\n",
    "            j += 1\n",
    "        return [a, b], c\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.steps <= 0: return  # Skip this on the last epoch.\n",
    "        self.steps -= 1\n",
    "        self.match = []\n",
    "        self.unmatch = []\n",
    "        _, _, x = lapjv(self.score)  # Solve the linear assignment problem\n",
    "        y = np.arange(len(x), dtype=np.int32)\n",
    "\n",
    "        # Compute a derangement for matching whales\n",
    "        for ts in w2ts.values():\n",
    "            d = ts.copy()\n",
    "            while True:\n",
    "                random.shuffle(d)\n",
    "                if not np.any(ts == d): break\n",
    "            for ab in zip(ts, d): self.match.append(ab)\n",
    "\n",
    "        # Construct unmatched whale pairs from the LAP solution.\n",
    "        for i, j in zip(x, y):\n",
    "            if i == j:\n",
    "                print(self.score)\n",
    "                print(x)\n",
    "                print(y)\n",
    "                print(i, j)\n",
    "            assert i != j\n",
    "            self.unmatch.append((train[i], train[j]))\n",
    "\n",
    "        # Force a different choice for an eventual next epoch.\n",
    "        self.score[x, y] = 10000.0\n",
    "        self.score[y, x] = 10000.0\n",
    "        random.shuffle(self.match)\n",
    "        random.shuffle(self.unmatch)\n",
    "        # print(len(self.match), len(train), len(self.unmatch), len(train))\n",
    "        assert len(self.match) == len(train) and len(self.unmatch) == len(train)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.match) + len(self.unmatch) + self.batch_size - 1) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a batch of 32 with random costs.\n",
    "score = np.random.random_sample(size=(len(train), len(train)))\n",
    "data = TrainingData(score)\n",
    "(a, b), c = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Keras generator to evaluate only the BRANCH MODEL\n",
    "class FeatureGen(Sequence):\n",
    "    def __init__(self, data, batch_size=64, verbose=1):\n",
    "        super(FeatureGen, self).__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        if self.verbose > 0: self.progress = tqdm(total=len(self), desc='Features')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = self.batch_size * index\n",
    "        size = min(len(self.data) - start, self.batch_size)\n",
    "        a = np.zeros((size,) + img_shape, dtype=K.floatx())\n",
    "        for i in range(size): a[i, :, :, :] = read_for_validation(self.data[start + i])\n",
    "        if self.verbose > 0:\n",
    "            self.progress.update()\n",
    "            if self.progress.n >= len(self): self.progress.close()\n",
    "        return a\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "\n",
    "class ScoreGen(Sequence):\n",
    "    def __init__(self, x, y=None, batch_size=2048, verbose=1):\n",
    "        super(ScoreGen, self).__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        if y is None:\n",
    "            self.y = self.x\n",
    "            self.ix, self.iy = np.triu_indices(x.shape[0], 1)\n",
    "        else:\n",
    "            self.iy, self.ix = np.indices((y.shape[0], x.shape[0]))\n",
    "            self.ix = self.ix.reshape((self.ix.size,))\n",
    "            self.iy = self.iy.reshape((self.iy.size,))\n",
    "        self.subbatch = (len(self.x) + self.batch_size - 1) // self.batch_size\n",
    "        if self.verbose > 0:\n",
    "            self.progress = tqdm(total=len(self), desc='Scores')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = min(start + self.batch_size, len(self.ix))\n",
    "        a = self.y[self.iy[start:end], :]\n",
    "        b = self.x[self.ix[start:end], :]\n",
    "        if self.verbose > 0:\n",
    "            self.progress.update()\n",
    "            if self.progress.n >= len(self): self.progress.close()\n",
    "        return [a, b]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.ix) + self.batch_size - 1) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lr(model, lr):\n",
    "    K.set_value(model.optimizer.lr, float(lr))\n",
    "\n",
    "\n",
    "def get_lr(model):\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "\n",
    "def score_reshape(score, x, y=None):\n",
    "    \"\"\"\n",
    "    Tranformed the packed matrix 'score' into a square matrix.\n",
    "    @param score the packed matrix\n",
    "    @param x the first image feature tensor\n",
    "    @param y the second image feature tensor if different from x\n",
    "    @result the square matrix\n",
    "    \"\"\"\n",
    "    if y is None:\n",
    "        # When y is None, score is a packed upper triangular matrix.\n",
    "        # Unpack, and transpose to form the symmetrical lower triangular matrix.\n",
    "        m = np.zeros((x.shape[0], x.shape[0]), dtype=K.floatx())\n",
    "        m[np.triu_indices(x.shape[0], 1)] = score.squeeze()\n",
    "        m += m.transpose()\n",
    "    else:\n",
    "        m = np.zeros((y.shape[0], x.shape[0]), dtype=K.floatx())\n",
    "        iy, ix = np.indices((y.shape[0], x.shape[0]))\n",
    "        ix = ix.reshape((ix.size,))\n",
    "        iy = iy.reshape((iy.size,))\n",
    "        m[iy, ix] = score.squeeze()\n",
    "    return m\n",
    "\n",
    "\n",
    "def compute_score(verbose=1):\n",
    "    \"\"\"\n",
    "    Compute the score matrix by scoring every pictures from the training set against every other picture O(n^2).\n",
    "    \"\"\"\n",
    "    features = branch_model.predict_generator(FeatureGen(train, verbose=verbose), max_queue_size=12, workers=16,\n",
    "                                              verbose=0)\n",
    "    score = head_model.predict_generator(ScoreGen(features, verbose=verbose), max_queue_size=12, workers=16, verbose=0)\n",
    "    score = score_reshape(score, features)\n",
    "    return features, score\n",
    "\n",
    "\n",
    "def make_steps(step, ampl):\n",
    "    \"\"\"\n",
    "    Perform training epochs\n",
    "    @param step Number of epochs to perform\n",
    "    @param ampl the K, the randomized component of the score matrix.\n",
    "    \"\"\"\n",
    "    global w2ts, t2i, steps, features, score, histories\n",
    "\n",
    "    # shuffle the training pictures\n",
    "    random.shuffle(train)\n",
    "\n",
    "    # Map whale id to the list of associated training picture hash value\n",
    "    w2ts = {}\n",
    "    for w, hs in w2hs.items():\n",
    "        for h in hs:\n",
    "            if h in train_set:\n",
    "                if w not in w2ts: w2ts[w] = []\n",
    "                if h not in w2ts[w]: w2ts[w].append(h)\n",
    "    for w, ts in w2ts.items(): w2ts[w] = np.array(ts)\n",
    "\n",
    "    # Map training picture hash value to index in 'train' array    \n",
    "    t2i = {}\n",
    "    for i, t in enumerate(train): t2i[t] = i\n",
    "\n",
    "    # Compute the match score for each picture pair\n",
    "    features, score = compute_score()\n",
    "\n",
    "    # Train the model for 'step' epochs\n",
    "    history = model.fit_generator(\n",
    "        TrainingData(score + ampl * np.random.random_sample(size=score.shape), steps=step, batch_size=32),\n",
    "        initial_epoch=steps, epochs=steps + step, max_queue_size=12, workers=16, verbose=1).history\n",
    "    steps += step\n",
    "\n",
    "    # Collect history data\n",
    "    history['epochs'] = steps\n",
    "    history['ms'] = np.mean(score)\n",
    "    history['lr'] = get_lr(model)\n",
    "    print(history['epochs'], history['lr'], history['ms'])\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(threshold, filename):\n",
    "    \"\"\"\n",
    "    Generate a Kaggle submission file.\n",
    "    @param threshold the score given to 'new_whale'\n",
    "    @param filename the submission file name\n",
    "    \"\"\"\n",
    "    vtop = 0\n",
    "    vhigh = 0\n",
    "    pos = [0, 0, 0, 0, 0, 0]\n",
    "    with open(filename, 'wt', newline='\\n') as f:\n",
    "        f.write('Image,Id\\n')\n",
    "        for i, p in enumerate(tqdm(submit)):\n",
    "            t = []\n",
    "            s = set()\n",
    "            a = score[i, :]\n",
    "            for j in list(reversed(np.argsort(a))):\n",
    "                h = known[j]\n",
    "                if a[j] < threshold and new_whale not in s:\n",
    "                    pos[len(t)] += 1\n",
    "                    s.add(new_whale)\n",
    "                    t.append(new_whale)\n",
    "                    if len(t) == 5: break;\n",
    "                for w in h2ws[h]:\n",
    "                    assert w != new_whale\n",
    "                    if w not in s:\n",
    "                        if a[j] > 1.0:\n",
    "                            vtop += 1\n",
    "                        elif a[j] >= threshold:\n",
    "                            vhigh += 1\n",
    "                        s.add(w)\n",
    "                        t.append(w)\n",
    "                        if len(t) == 5: break;\n",
    "                if len(t) == 5: break;\n",
    "            if new_whale not in s: pos[5] += 1\n",
    "            assert len(t) == 5 and len(s) == 5\n",
    "            f.write(p + ',' + ' '.join(t[:5]) + '\\n')\n",
    "    return vtop, vhigh, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526202cd036f4e71b5f1beceb9bc79d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=246, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/246 [============================>.] - ETA: 2s\n",
      "246/246 [==============================] - 171s 694ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e72672704ed46e0914f0416097148a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=125, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/125 [===========================>..] - ETA: 3s\n",
      "125/125 [==============================] - 93s 745ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a671cb50ec843b4b65bc8fa3a681b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=61006, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60980/61006 [============================>.] - ETA: 0s\n",
      "61006/61006 [==============================] - 533s 9ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a31bead891047679a83d309b4d3fe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=246, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/246 [============================>.] - ETA: 1s\n",
      "246/246 [==============================] - 166s 673ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9655d771e2664208b1900785060d0217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=125, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/125 [===========================>..] - ETA: 4s\n",
      "125/125 [==============================] - 83s 667ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da56be94fd444659df0323c7798944b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=61006, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60979/61006 [============================>.] - ETA: 0s\n",
      "61006/61006 [==============================] - 579s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "steps = 0\n",
    "\n",
    "#############################\n",
    "# Load standard model and compute score \n",
    "tmp = keras.models.load_model('standard-10.model')\n",
    "model.set_weights(tmp.get_weights())\n",
    "\n",
    "# Find elements from training sets not 'new_whale'\n",
    "tic = time.time()\n",
    "h2ws = {}\n",
    "for p, w in tagged.items():\n",
    "    if w != new_whale:  # Use only identified whales\n",
    "        h = p2h[p]\n",
    "        if h not in h2ws: h2ws[h] = []\n",
    "        if w not in h2ws[h]: h2ws[h].append(w)\n",
    "known = sorted(list(h2ws.keys()))\n",
    "\n",
    "# Dictionary of picture indices\n",
    "h2i = {}\n",
    "for i, h in enumerate(known): h2i[h] = i\n",
    "\n",
    "# Evaluate the model.\n",
    "fknown1 = branch_model.predict_generator(FeatureGen(known), max_queue_size=20, workers=16, verbose=1)\n",
    "fsubmit1 = branch_model.predict_generator(FeatureGen(submit), max_queue_size=20, workers=16, verbose=1)\n",
    "score1 = head_model.predict_generator(ScoreGen(fknown1, fsubmit1), max_queue_size=20, workers=16, verbose=1)\n",
    "score1 = score_reshape(score1, fknown1, fsubmit1)\n",
    "\n",
    "###########################\n",
    "# Load bootstrap model and compute score \n",
    "tmp = keras.models.load_model('../data/models/mpiotte-bootstrap.model')\n",
    "model.set_weights(tmp.get_weights())\n",
    "\n",
    "# Find elements from training sets not 'new_whale'\n",
    "tic = time.time()\n",
    "h2ws = {}\n",
    "for p, w in tagged.items():\n",
    "    if w != new_whale:  # Use only identified whales\n",
    "        h = p2h[p]\n",
    "        if h not in h2ws: h2ws[h] = []\n",
    "        if w not in h2ws[h]: h2ws[h].append(w)\n",
    "known = sorted(list(h2ws.keys()))\n",
    "\n",
    "# Dictionary of picture indices\n",
    "h2i = {}\n",
    "for i, h in enumerate(known): h2i[h] = i\n",
    "\n",
    "# Evaluate the model.\n",
    "fknown2 = branch_model.predict_generator(FeatureGen(known), max_queue_size=20, workers=16, verbose=1)\n",
    "fsubmit2 = branch_model.predict_generator(FeatureGen(submit), max_queue_size=20, workers=16, verbose=1)\n",
    "score2 = head_model.predict_generator(ScoreGen(fknown2, fsubmit2), max_queue_size=20, workers=16, verbose=1)\n",
    "score2 = score_reshape(score2, fknown2, fsubmit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1627bac7e1f4bfcb22fe0fa2b4b4847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e603b5a1fbd84c098418cadbac155d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "852/852 [==============================] - 741s 870ms/step - loss: 0.2061 - binary_crossentropy: 0.2061 - acc: 0.9213\n",
      "Epoch 2/10\n",
      "852/852 [==============================] - 688s 808ms/step - loss: 0.1505 - binary_crossentropy: 0.1505 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "852/852 [==============================] - 737s 865ms/step - loss: 0.1491 - binary_crossentropy: 0.1491 - acc: 0.9415\n",
      "Epoch 4/10\n",
      "852/852 [==============================] - 690s 809ms/step - loss: 0.1479 - binary_crossentropy: 0.1479 - acc: 0.9406\n",
      "Epoch 5/10\n",
      "852/852 [==============================] - 696s 817ms/step - loss: 0.1405 - binary_crossentropy: 0.1405 - acc: 0.9452\n",
      "Epoch 6/10\n",
      "852/852 [==============================] - 702s 823ms/step - loss: 0.1414 - binary_crossentropy: 0.1414 - acc: 0.9435\n",
      "Epoch 7/10\n",
      "852/852 [==============================] - 725s 851ms/step - loss: 0.1363 - binary_crossentropy: 0.1363 - acc: 0.9461\n",
      "Epoch 8/10\n",
      "852/852 [==============================] - 642s 753ms/step - loss: 0.1331 - binary_crossentropy: 0.1331 - acc: 0.9451\n",
      "Epoch 9/10\n",
      "852/852 [==============================] - 675s 792ms/step - loss: 0.1237 - binary_crossentropy: 0.1237 - acc: 0.9505\n",
      "Epoch 10/10\n",
      "852/852 [==============================] - 552s 648ms/step - loss: 0.1220 - binary_crossentropy: 0.1220 - acc: 0.9521\n",
      "10 0.00064 0.002726098\n",
      "noise ampl.  =  100.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed3bfc7725243fba659417635dee439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b267d6a2d3c4a97b04fd4a5bd27aef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/15\n",
      "852/852 [==============================] - 603s 708ms/step - loss: 0.3073 - binary_crossentropy: 0.3073 - acc: 0.8670\n",
      "Epoch 12/15\n",
      "852/852 [==============================] - 600s 704ms/step - loss: 0.2450 - binary_crossentropy: 0.2450 - acc: 0.8968\n",
      "Epoch 13/15\n",
      "852/852 [==============================] - 630s 739ms/step - loss: 0.2072 - binary_crossentropy: 0.2072 - acc: 0.9136\n",
      "Epoch 14/15\n",
      "852/852 [==============================] - 639s 750ms/step - loss: 0.1888 - binary_crossentropy: 0.1888 - acc: 0.9223\n",
      "Epoch 15/15\n",
      "852/852 [==============================] - 552s 648ms/step - loss: 0.1699 - binary_crossentropy: 0.1699 - acc: 0.9312\n",
      "15 0.00064 0.085166946\n",
      "noise ampl.  =  63.09573444801933\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6ff76fb47e47f88ea34d7662525546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1914f873934545808b002ed889fe4ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20\n",
      "852/852 [==============================] - 678s 795ms/step - loss: 0.2658 - binary_crossentropy: 0.2658 - acc: 0.8846\n",
      "Epoch 17/20\n",
      "852/852 [==============================] - 741s 869ms/step - loss: 0.2096 - binary_crossentropy: 0.2096 - acc: 0.9116\n",
      "Epoch 18/20\n",
      "852/852 [==============================] - 835s 980ms/step - loss: 0.1827 - binary_crossentropy: 0.1827 - acc: 0.9245\n",
      "Epoch 19/20\n",
      "852/852 [==============================] - 910s 1s/step - loss: 0.1659 - binary_crossentropy: 0.1659 - acc: 0.9312\n",
      "Epoch 20/20\n",
      "852/852 [==============================] - 549s 645ms/step - loss: 0.1494 - binary_crossentropy: 0.1494 - acc: 0.9378\n",
      "20 0.00064 0.03765761\n"
     ]
    }
   ],
   "source": [
    "# epoch -> 10\n",
    "make_steps(10, 1000)\n",
    "ampl = 100.0\n",
    "for _ in range(2):\n",
    "    print('noise ampl.  = ', ampl)\n",
    "    make_steps(5, ampl)\n",
    "    ampl = max(1.0, 100 ** -0.1 * ampl)\n",
    "model.save('standard-10.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82818e447be94a5789444d95a36f3d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9088e8ef19914f3bbd63b0218468e3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/25\n",
      "852/852 [==============================] - 595s 699ms/step - loss: 0.3357 - binary_crossentropy: 0.3357 - acc: 0.8552\n",
      "Epoch 22/25\n",
      "852/852 [==============================] - 597s 701ms/step - loss: 0.2739 - binary_crossentropy: 0.2739 - acc: 0.8838\n",
      "Epoch 23/25\n",
      "852/852 [==============================] - 603s 708ms/step - loss: 0.2486 - binary_crossentropy: 0.2486 - acc: 0.8977\n",
      "Epoch 24/25\n",
      "852/852 [==============================] - 606s 711ms/step - loss: 0.2347 - binary_crossentropy: 0.2347 - acc: 0.9043\n",
      "Epoch 25/25\n",
      "852/852 [==============================] - 551s 646ms/step - loss: 0.2186 - binary_crossentropy: 0.2186 - acc: 0.9105\n",
      "25 0.00064 0.025107086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e07d6d8fb747b18ce75bfb332eba5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76106797f71841f5a5c8534fa7bc05f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/30\n",
      "852/852 [==============================] - 659s 774ms/step - loss: 0.2791 - binary_crossentropy: 0.2791 - acc: 0.8833\n",
      "Epoch 27/30\n",
      "852/852 [==============================] - 695s 816ms/step - loss: 0.2210 - binary_crossentropy: 0.2210 - acc: 0.9112\n",
      "Epoch 28/30\n",
      "852/852 [==============================] - 757s 889ms/step - loss: 0.2062 - binary_crossentropy: 0.2062 - acc: 0.9175\n",
      "Epoch 29/30\n",
      "852/852 [==============================] - 829s 973ms/step - loss: 0.1896 - binary_crossentropy: 0.1896 - acc: 0.9247\n",
      "Epoch 30/30\n",
      "852/852 [==============================] - 549s 644ms/step - loss: 0.1811 - binary_crossentropy: 0.1811 - acc: 0.9281\n",
      "30 0.00064 0.026784025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe152af19644960bd4eabda6852b895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1df76200ce4324b468d06642b51e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/35\n",
      "852/852 [==============================] - 642s 753ms/step - loss: 0.2539 - binary_crossentropy: 0.2539 - acc: 0.8964\n",
      "Epoch 32/35\n",
      "852/852 [==============================] - 680s 798ms/step - loss: 0.2055 - binary_crossentropy: 0.2055 - acc: 0.9200\n",
      "Epoch 33/35\n",
      "852/852 [==============================] - 720s 845ms/step - loss: 0.1857 - binary_crossentropy: 0.1857 - acc: 0.9265\n",
      "Epoch 34/35\n",
      "852/852 [==============================] - 777s 912ms/step - loss: 0.1707 - binary_crossentropy: 0.1707 - acc: 0.9327\n",
      "Epoch 35/35\n",
      "852/852 [==============================] - 554s 650ms/step - loss: 0.1619 - binary_crossentropy: 0.1619 - acc: 0.9370\n",
      "35 0.00064 0.021102527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294b728894064cf7afd615a84ac37671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6d7ff6dfcb484fb17a8175d5cc8039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/40\n",
      "852/852 [==============================] - 687s 807ms/step - loss: 0.2338 - binary_crossentropy: 0.2338 - acc: 0.9056\n",
      "Epoch 37/40\n",
      "852/852 [==============================] - 765s 898ms/step - loss: 0.1848 - binary_crossentropy: 0.1848 - acc: 0.9287\n",
      "Epoch 38/40\n",
      "852/852 [==============================] - 843s 990ms/step - loss: 0.1647 - binary_crossentropy: 0.1647 - acc: 0.9354\n",
      "Epoch 39/40\n",
      "852/852 [==============================] - 944s 1s/step - loss: 0.1512 - binary_crossentropy: 0.1512 - acc: 0.9425\n",
      "Epoch 40/40\n",
      "852/852 [==============================] - 550s 646ms/step - loss: 0.1464 - binary_crossentropy: 0.1464 - acc: 0.9418\n",
      "40 0.00064 0.024891052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34c70210afc4162a68342c4521d4af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbe1906f377446cbfb46db3aae46e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41/45\n",
      "852/852 [==============================] - 785s 922ms/step - loss: 0.2274 - binary_crossentropy: 0.2274 - acc: 0.9101\n",
      "Epoch 42/45\n",
      "852/852 [==============================] - 917s 1s/step - loss: 0.1850 - binary_crossentropy: 0.1850 - acc: 0.9263\n",
      "Epoch 43/45\n",
      "852/852 [==============================] - 1062s 1s/step - loss: 0.1627 - binary_crossentropy: 0.1627 - acc: 0.9379\n",
      "Epoch 44/45\n",
      "852/852 [==============================] - 1190s 1s/step - loss: 0.1526 - binary_crossentropy: 0.1526 - acc: 0.9401\n",
      "Epoch 45/45\n",
      "852/852 [==============================] - 551s 647ms/step - loss: 0.1397 - binary_crossentropy: 0.1397 - acc: 0.9447\n",
      "45 0.00064 0.018267082\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e950cc73a443e3bc70a6ffff05e8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d6d4dbe828434cb3d0456d0692b147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/50\n",
      "852/852 [==============================] - 829s 974ms/step - loss: 0.2167 - binary_crossentropy: 0.2167 - acc: 0.9121\n",
      "Epoch 47/50\n",
      "852/852 [==============================] - 938s 1s/step - loss: 0.1694 - binary_crossentropy: 0.1694 - acc: 0.9350\n",
      "Epoch 48/50\n",
      "852/852 [==============================] - 1046s 1s/step - loss: 0.1571 - binary_crossentropy: 0.1571 - acc: 0.9379\n",
      "Epoch 49/50\n",
      "852/852 [==============================] - 1288s 2s/step - loss: 0.1376 - binary_crossentropy: 0.1376 - acc: 0.9465\n",
      "Epoch 50/50\n",
      "852/852 [==============================] - 550s 645ms/step - loss: 0.1318 - binary_crossentropy: 0.1318 - acc: 0.9485\n",
      "50 0.00064 0.021822374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5272fcd4184d6698c3a110912a1aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c238d45feb847a4acf328bedb1c44bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51/55\n",
      "852/852 [==============================] - 907s 1s/step - loss: 0.2015 - binary_crossentropy: 0.2015 - acc: 0.9172\n",
      "Epoch 52/55\n",
      "852/852 [==============================] - 1024s 1s/step - loss: 0.1635 - binary_crossentropy: 0.1635 - acc: 0.9348\n",
      "Epoch 53/55\n",
      "852/852 [==============================] - 1205s 1s/step - loss: 0.1461 - binary_crossentropy: 0.1461 - acc: 0.9439\n",
      "Epoch 54/55\n",
      "852/852 [==============================] - 1400s 2s/step - loss: 0.1374 - binary_crossentropy: 0.1374 - acc: 0.9464\n",
      "Epoch 55/55\n",
      "852/852 [==============================] - 553s 649ms/step - loss: 0.1299 - binary_crossentropy: 0.1299 - acc: 0.9493\n",
      "55 0.00064 0.012899656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7059ab65e4394a459b2f26b9714899bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Features', max=213, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5778d1815ea9400c87719146f0852b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Scores', max=45306, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56/60\n",
      "852/852 [==============================] - 1212s 1s/step - loss: 0.2004 - binary_crossentropy: 0.2004 - acc: 0.9202\n",
      "Epoch 57/60\n",
      "852/852 [==============================] - 1522s 2s/step - loss: 0.1526 - binary_crossentropy: 0.1526 - acc: 0.9404\n",
      "Epoch 58/60\n",
      "852/852 [==============================] - 1812s 2s/step - loss: 0.1380 - binary_crossentropy: 0.1380 - acc: 0.9470\n",
      "Epoch 59/60\n",
      "851/852 [============================>.] - ETA: 0s - loss: 0.1341 - binary_crossentropy: 0.1341 - acc: 0.9474"
     ]
    }
   ],
   "source": [
    "# epoch -> 150\n",
    "for _ in range(18): make_steps(5, 1.0)\n",
    "model.save('standard-150.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch -> 200\n",
    "set_lr(model, 16e-5)\n",
    "for _ in range(10): make_steps(5, 0.5)\n",
    "model.save('standard-200.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch -> 240\n",
    "set_lr(model, 4e-5)\n",
    "for _ in range(8): make_steps(5, 0.25)\n",
    "model.save('standard-240.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch -> 250\n",
    "set_lr(model, 1e-5)\n",
    "for _ in range(2): make_steps(5, 0.25)\n",
    "model.save('standard-250.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch -> 300\n",
    "weights = model.get_weights()\n",
    "model, branch_model, head_model = build_model(64e-5, 0.0002)\n",
    "model.set_weights(weights)\n",
    "for _ in range(10): make_steps(5, 1.0)\n",
    "model.save('standard-300.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch -> 350\n",
    "set_lr(model, 16e-5)\n",
    "for _ in range(10): make_steps(5, 0.5)\n",
    "model.save('standard-350.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch -> 390\n",
    "set_lr(model, 4e-5)\n",
    "for _ in range(8): make_steps(5, 0.25)\n",
    "model.save('standard-390.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch -> 400\n",
    "set_lr(model, 1e-5)\n",
    "for _ in range(2): make_steps(5, 0.25)\n",
    "model.save('standard-400.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the weighthing exaclty as Martin suggests\n",
    "score = 0.45*score1 + 0.55*score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d762f721426420092f87e66b4f4b139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7960), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission time:  19.918695465723673\n"
     ]
    }
   ],
   "source": [
    "# Generate the subsmission file.\n",
    "prepare_submission(0.92, '19_submission_0.45_standard_0.55_boostrap.csv')\n",
    "toc = time.time()\n",
    "print(\"Submission time: \", (toc - tic) / 60.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
